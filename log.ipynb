{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Файл лога, в котором фиксируются пройденный материал.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "27/01/25\n",
    "\n",
    "1. Создала аккаунт на GitHub и оформила его, использовав примеры из шаблонов.\n",
    "2. Создала аккаунт на Kaggle и получила статус контрибьютора.\n",
    "3. Создала аккаунт на ODS.AI.\n",
    "4. Скачала и установила GitHub Desktop и Cursor, проверила настройки ранее установленного VS Code.\n",
    "5. Установила плагины, настроила Cursor и VS Code к работе.\n",
    "6. Установила CPython, Git и Conda.\n",
    "7. Создала джамборд для учебы в canva.\n",
    "8. Склонировала репозиторий, присоединилась к команде и создала свою ветку.\n",
    "9. Запустила проверку файлов в репозитории командой pre-commit run --all-files.\n",
    "10. Ознакомилась с процессом принятия и отправки коммитов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "27/01/25\n",
    "\n",
    "1. Введение в линейную регрессию. \n",
    "- 1.1 Метод наименьших квадратов применяется для подбора коэфициентов в линейной регрессии (он оценивает параметры регрессии). \n",
    "- 1.2 если данные поддаются линейным взаимосвязям, то мы можем применять линейную модель. \n",
    "2. Машинное обучение. 2 большие группы - с учителем и без учителя. \n",
    "- 2.1 Обучение с учителем: а) регрессионные модели и б) классификационные. \n",
    "- 2.2 Без учителя: кластеризация. \n",
    "3. Рассмотрели порядок обучения модели. \n",
    "4. Закон нормального распределения. \n",
    "- 4.1 Описывает, как часто различные значения случайной величины встречаются в наборе данных. \n",
    "- 4.2 Математическое ожидание — это среднее значение случайной величины. \n",
    "- 4.3 PDF - график плотности случайной величины. \n",
    "5. Метод наименьших квадратов (для подбора весов). \n",
    "- 5.1 Его задача - минимизировать сумму квадратов регрессионных остатков. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "02/02/25\n",
    "\n",
    "1. Теорема Гаусса Маркова: МНК является лучшей линейной несмещенной оценкой. \n",
    "- 1.1 Несмещенная модель. Суть: когда мы можем взять какое-то подмножество точек из целого множества, и математическое ожидание этого подмножества будет совпадать с таковым у самого множества. \n",
    "- 1.2 Гомоскедастичность - свойство, означающее постоянство условной дисперсии вектора или последовательности случайных величин. Означает одинаковый разброс величин относительно нашей линии фита. \n",
    "\n",
    "- Как наглядно выглядят гомоскедастичность и гетероскедастичность:\n",
    "![Гетероскедастичность](https://myslide.ru/documents_3/2b677335f0177d29121e558fe4d3215c/img3.jpg)\n",
    "\n",
    "2. Математическое ожидание. \n",
    "3. Понятие дисперсии и стандартного отклонения. Если дисперсия фиксирована и не зависит от входных данных, такая модель называется гомоскедастической регрессией, а если зависит - гетероскедастической. \n",
    "4. Понятия средняя, медиана и мода. \n",
    "- 4.1 Робастная оценка - это и есть медиана, устойчива к выбросам. \n",
    "- 4.2 Среднее - сумма всех значений деленная на количество этих значений. \n",
    "- 4.2 Медиана - значение, которое делит отсортированный набор на две равные части. \n",
    "- 4.3 Мода - значение, которое встречается в выборке чаще всего. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
